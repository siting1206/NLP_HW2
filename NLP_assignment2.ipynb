{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siting1206/NLP_HW2/blob/main/NLP_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9qSQznciRmm",
        "outputId": "8b7553c7-e58c-414d-dd67-2d31e8a3dc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install pandas nltk\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meapTOr9jNtc",
        "outputId": "53cc7f66-9320-4c35-cb79-dfda53e40457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjPT6rNKjThm",
        "outputId": "b113c094-4b5f-4d38-dcd2-14f2d68b64a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch, pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "\n",
        "from transformers import set_seed\n",
        "set_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "sybq-JAujXLn"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/NLP_assignment2/Dataset/train_ret.txt', sep='\\t')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/NLP_assignment2/Dataset/valid_ret.txt', sep='\\t')\n",
        "train_df[['snippet','question','answer']] = train_df[['snippet','question','answer']].apply(lambda x: x.str.strip('\\\"'))\n",
        "valid_df[['snippet','question','answer']] = valid_df[['snippet','question','answer']].apply(lambda x: x.str.strip('\\\"'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gnv0Is2D6GtT",
        "outputId": "9c24d2aa-ab98-430e-e382-5d1f0ab3d611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             snippet  \\\n",
              "0  lebowski sweater replica jun 17 , 2013 history...   \n",
              "1  assignment 13 nov 30 , 2014 2 1912 olympian fo...   \n",
              "2  weather world records average , yuma receives ...   \n",
              "3  gravestone famous ancestor roger sherman signe...   \n",
              "4  assignment 13 nov 30 , 2014 united states 6 ti...   \n",
              "\n",
              "                                            question      answer  \n",
              "0  last 8 years life , galileo house arrest espou...  copernicus  \n",
              "1  2 1912 olympian football star carlisle indian ...  jim thorpe  \n",
              "2  city yuma state record average 4 , 055 hours s...     arizona  \n",
              "3  signer dec indep , framer constitution mass , ...  john adams  \n",
              "4  title aesop fable , insect shared billing gras...         ant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c899cb4-4ccb-4ce6-bc5c-de96c40440bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snippet</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lebowski sweater replica jun 17 , 2013 history...</td>\n",
              "      <td>last 8 years life , galileo house arrest espou...</td>\n",
              "      <td>copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>assignment 13 nov 30 , 2014 2 1912 olympian fo...</td>\n",
              "      <td>2 1912 olympian football star carlisle indian ...</td>\n",
              "      <td>jim thorpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weather world records average , yuma receives ...</td>\n",
              "      <td>city yuma state record average 4 , 055 hours s...</td>\n",
              "      <td>arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gravestone famous ancestor roger sherman signe...</td>\n",
              "      <td>signer dec indep , framer constitution mass , ...</td>\n",
              "      <td>john adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>assignment 13 nov 30 , 2014 united states 6 ti...</td>\n",
              "      <td>title aesop fable , insect shared billing gras...</td>\n",
              "      <td>ant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c899cb4-4ccb-4ce6-bc5c-de96c40440bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c899cb4-4ccb-4ce6-bc5c-de96c40440bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c899cb4-4ccb-4ce6-bc5c-de96c40440bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z2Ubkt2BVCxF",
        "outputId": "32d3824d-2732-4379-a61d-3dc803632a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             snippet  \\\n",
              "0  free flashcards authors studystack spain 1959 ...   \n",
              "1  lowest highest death valley mt whitney walk ba...   \n",
              "2  banking peril barron 's apr 5 , 2010 take hub ...   \n",
              "3  direct essays mickey mouse steamboat willie ka...   \n",
              "4  old world capitals eastern europe vacations , ...   \n",
              "\n",
              "                                            question       answer  \n",
              "0  spain 1959 , wrote dangerous summer , story ri...    hemingway  \n",
              "1  valley 282 feet sea level state lowest point w...   california  \n",
              "2  like banks , many grocery stores dispensing ca...         atms  \n",
              "3               voice mickey mouse steamboat willie   walt disney  \n",
              "4         eastern european capital city 2 2 million     bucharest  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d360dcea-e3e3-426f-8acb-29005a3821c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snippet</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>free flashcards authors studystack spain 1959 ...</td>\n",
              "      <td>spain 1959 , wrote dangerous summer , story ri...</td>\n",
              "      <td>hemingway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lowest highest death valley mt whitney walk ba...</td>\n",
              "      <td>valley 282 feet sea level state lowest point w...</td>\n",
              "      <td>california</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>banking peril barron 's apr 5 , 2010 take hub ...</td>\n",
              "      <td>like banks , many grocery stores dispensing ca...</td>\n",
              "      <td>atms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>direct essays mickey mouse steamboat willie ka...</td>\n",
              "      <td>voice mickey mouse steamboat willie</td>\n",
              "      <td>walt disney</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>old world capitals eastern europe vacations , ...</td>\n",
              "      <td>eastern european capital city 2 2 million</td>\n",
              "      <td>bucharest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d360dcea-e3e3-426f-8acb-29005a3821c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d360dcea-e3e3-426f-8acb-29005a3821c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d360dcea-e3e3-426f-8acb-29005a3821c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "eZ_GIS9ihmtq"
      },
      "outputs": [],
      "source": [
        "# train_df['ans_start'] = [y.index(x) if str(x) in y else 0 for x,y in zip(train_df[\"answer\"], train_df[\"snippet\"])]\n",
        "# train_df['ans_end'] = [x+len(y)-1 if x!=0 else 0 for x,y in zip(train_df[\"ans_start\"], train_df[\"answer\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "MIMAzX1p3_4_"
      },
      "outputs": [],
      "source": [
        "train_df['ans_start'] = [y.index(x)+len(str(z)) if str(x) in y else 0 for x,y,z in zip(train_df[\"answer\"], train_df[\"snippet\"], train_df[\"question\"])]\n",
        "train_df['ans_end'] = [x+len(y)-1 if x!=0 else 0 for x,y,z in zip(train_df[\"ans_start\"], train_df[\"answer\"], train_df[\"question\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "uMaftAZQVeMW"
      },
      "outputs": [],
      "source": [
        "valid_df['ans_start'] = [y.index(x)+len(str(z)) if str(x) in y else 0 for x,y,z in zip(valid_df[\"answer\"], valid_df[\"snippet\"], valid_df[\"question\"])]\n",
        "valid_df['ans_end'] = [x+len(y)-1 if x!=0 else 0 for x,y,z in zip(valid_df[\"ans_start\"], valid_df[\"answer\"], valid_df[\"question\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VbEgzWRRE9F_",
        "outputId": "793023d3-2eda-4812-97c5-2077516be804"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             snippet  \\\n",
              "0  lebowski sweater replica jun 17 , 2013 history...   \n",
              "1  assignment 13 nov 30 , 2014 2 1912 olympian fo...   \n",
              "2  weather world records average , yuma receives ...   \n",
              "3  gravestone famous ancestor roger sherman signe...   \n",
              "4  assignment 13 nov 30 , 2014 united states 6 ti...   \n",
              "\n",
              "                                            question      answer  ans_start  \\\n",
              "0  last 8 years life , galileo house arrest espou...  copernicus        177   \n",
              "1  2 1912 olympian football star carlisle indian ...  jim thorpe          0   \n",
              "2  city yuma state record average 4 , 055 hours s...     arizona          0   \n",
              "3  signer dec indep , framer constitution mass , ...  john adams        252   \n",
              "4  title aesop fable , insect shared billing gras...         ant          0   \n",
              "\n",
              "   ans_end  \n",
              "0      186  \n",
              "1        0  \n",
              "2        0  \n",
              "3      261  \n",
              "4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbc424d2-873a-447a-bab6-0b18bd638dfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snippet</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>ans_start</th>\n",
              "      <th>ans_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lebowski sweater replica jun 17 , 2013 history...</td>\n",
              "      <td>last 8 years life , galileo house arrest espou...</td>\n",
              "      <td>copernicus</td>\n",
              "      <td>177</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>assignment 13 nov 30 , 2014 2 1912 olympian fo...</td>\n",
              "      <td>2 1912 olympian football star carlisle indian ...</td>\n",
              "      <td>jim thorpe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weather world records average , yuma receives ...</td>\n",
              "      <td>city yuma state record average 4 , 055 hours s...</td>\n",
              "      <td>arizona</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gravestone famous ancestor roger sherman signe...</td>\n",
              "      <td>signer dec indep , framer constitution mass , ...</td>\n",
              "      <td>john adams</td>\n",
              "      <td>252</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>assignment 13 nov 30 , 2014 united states 6 ti...</td>\n",
              "      <td>title aesop fable , insect shared billing gras...</td>\n",
              "      <td>ant</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbc424d2-873a-447a-bab6-0b18bd638dfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbc424d2-873a-447a-bab6-0b18bd638dfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbc424d2-873a-447a-bab6-0b18bd638dfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TRO_OiYSVl4H",
        "outputId": "c559e3a8-a0f4-440f-cb3e-b9541c84000a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             snippet  \\\n",
              "0  free flashcards authors studystack spain 1959 ...   \n",
              "1  lowest highest death valley mt whitney walk ba...   \n",
              "2  banking peril barron 's apr 5 , 2010 take hub ...   \n",
              "3  direct essays mickey mouse steamboat willie ka...   \n",
              "4  old world capitals eastern europe vacations , ...   \n",
              "\n",
              "                                            question       answer  ans_start  \\\n",
              "0  spain 1959 , wrote dangerous summer , story ri...    hemingway        163   \n",
              "1  valley 282 feet sea level state lowest point w...   california          0   \n",
              "2  like banks , many grocery stores dispensing ca...         atms          0   \n",
              "3               voice mickey mouse steamboat willie   walt disney          0   \n",
              "4         eastern european capital city 2 2 million     bucharest          0   \n",
              "\n",
              "   ans_end  \n",
              "0      171  \n",
              "1        0  \n",
              "2        0  \n",
              "3        0  \n",
              "4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-200075a6-9adb-4df9-8152-28add35b9db5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snippet</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>ans_start</th>\n",
              "      <th>ans_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>free flashcards authors studystack spain 1959 ...</td>\n",
              "      <td>spain 1959 , wrote dangerous summer , story ri...</td>\n",
              "      <td>hemingway</td>\n",
              "      <td>163</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lowest highest death valley mt whitney walk ba...</td>\n",
              "      <td>valley 282 feet sea level state lowest point w...</td>\n",
              "      <td>california</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>banking peril barron 's apr 5 , 2010 take hub ...</td>\n",
              "      <td>like banks , many grocery stores dispensing ca...</td>\n",
              "      <td>atms</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>direct essays mickey mouse steamboat willie ka...</td>\n",
              "      <td>voice mickey mouse steamboat willie</td>\n",
              "      <td>walt disney</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>old world capitals eastern europe vacations , ...</td>\n",
              "      <td>eastern european capital city 2 2 million</td>\n",
              "      <td>bucharest</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-200075a6-9adb-4df9-8152-28add35b9db5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-200075a6-9adb-4df9-8152-28add35b9db5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-200075a6-9adb-4df9-8152-28add35b9db5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L6q_jUaUImB"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3W031LNKFgkV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "BKGsIQniUOl3"
      },
      "outputs": [],
      "source": [
        "train_data_s = train_df['snippet'].tolist()\n",
        "valid_data_s = valid_df['snippet'].tolist()\n",
        "\n",
        "train_data_q = train_df['question'].tolist()\n",
        "valid_data_q = valid_df['question'].tolist()\n",
        "# for i in range(0,len(train_data_q)):\n",
        "#   if type(train_data_q[i]) == float:\n",
        "#     print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0g5fta71WrS8"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_data_q, train_data_s, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(valid_data_q, valid_data_s, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "XEvFLlzOVtSy",
        "outputId": "812437bf-efcd-46cc-cf42-e96ed3151bef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] last 8 years life, galileo house arrest espousing man's theory [SEP] lebowski sweater replica jun 17, 2013 history last 8 years life, galileo house arrest espousing man's theory copernicus espn's top 10 time [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "kFcLpqvskUNR",
        "outputId": "6b38dcd7-033f-4c30-bd23-a7225c7870b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] spain 1959, wrote dangerous summer, story rival bullfighters [SEP] free flashcards authors studystack spain 1959, wrote dangerous summer, story rival bullfighters, hemingway 1884 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "tokenizer.decode(val_encodings['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-QZEPNOwXV9n"
      },
      "outputs": [],
      "source": [
        "train_answer = train_df[['ans_start', 'ans_end']].to_dict('records')\n",
        "valid_answer = valid_df[['ans_start', 'ans_end']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "w1AGssrmXvBH"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    ans_start, ans_end = [],[]\n",
        "\n",
        "    for i in range(len(answers)):\n",
        "        ans_start.append(encodings.char_to_token(i, answers[i]['ans_start'], 0))\n",
        "        ans_end.append(encodings.char_to_token(i, answers[i]['ans_end'], 0))\n",
        "\n",
        "        if ans_start[-1] is None:\n",
        "            ans_start[-1] = 0\n",
        "            ans_end[-1] = 0\n",
        "            # continue\n",
        "\n",
        "        shift = 1\n",
        "        while ans_end[-1] is None:\n",
        "            ans_end[-1] = encodings.char_to_token(i, answers[i]['ans_end'] - shift)\n",
        "            shift += 1\n",
        "    encodings.update({'ans_start':ans_start, 'ans_end':ans_end})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "s-mnkgTXZIbW"
      },
      "outputs": [],
      "source": [
        "# Convert char_based_id to token_based_id\n",
        "# Find the corossponding token id after input being tokenized\n",
        "add_token_positions(train_encodings, train_answer)\n",
        "add_token_positions(val_encodings, valid_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mk6bMkqZY3D",
        "outputId": "5a1e7d40-f948-4578-b9da-93b811fa16cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'ans_start', 'ans_end'])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "train_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnTQgiUgZb6v",
        "outputId": "51f188b7-2ec6-44a2-feee-d659157920fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(train_encodings['ans_start'][0])\n",
        "print(train_encodings['ans_end'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "PVYqy-8ZZpf3"
      },
      "outputs": [],
      "source": [
        "class qrDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "oFnNTAJVZsNf"
      },
      "outputs": [],
      "source": [
        "train_dataset = qrDataset(train_encodings)\n",
        "valid_dataset = qrDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n3-FfH1Z3G_",
        "outputId": "98561452-1f52-469b-a59e-898343341b73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  1314,   129,  1201,  1297,   117, 20003,  4759,  1186,  1402,\n",
              "          6040, 13936,  5674, 19578,  1299,   112,   188,  2749,   102,  5837,\n",
              "         14251,  5437, 15195, 16498,   179,  3488,  1542,   117,  1381,  1607,\n",
              "          1314,   129,  1201,  1297,   117, 20003,  4759,  1186,  1402,  6040,\n",
              "         13936,  5674, 19578,  1299,   112,   188,  2749, 16743,  4558, 14191,\n",
              "         13936,  1643,  1179,   112,   188,  1499,  1275,  1159,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'ans_start': tensor(0),\n",
              " 'ans_end': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "next(iter(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27lH1qUdZ6gK"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "y2lMSQ_LZ6Ua"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "class myModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(myModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.fc = nn.Linear(768, 2)\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
        "        logits = output[0]\n",
        "        out = self.fc(logits)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8zZGqGaYed"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TelNW-BGaTgo",
        "outputId": "fe710a00-32f6-4246-aca6-59ef771d8031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set GPU / CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# Put model on device\n",
        "model = myModel().to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "e36hyUjXabsC"
      },
      "outputs": [],
      "source": [
        "# Pack data into dataloader by batch\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "UiDJHGFDavON"
      },
      "outputs": [],
      "source": [
        "training_epoch = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "unW13vsWaxsH"
      },
      "outputs": [],
      "source": [
        "loss_fct = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "VrTQrYsjazsZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(valid_loader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(valid_loader, leave=True)\n",
        "        for batch_id, batch in enumerate(loop):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            token_type_ids = batch['token_type_ids'].to(device)\n",
        "            ans_start = batch['ans_start'].to(device)\n",
        "            ans_end = batch['ans_end'].to(device)\n",
        "\n",
        "            # model output\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            ans_start_logits, ans_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "            ans_start_logits = ans_start_logits.squeeze(-1).contiguous()\n",
        "            ans_end_logits = ans_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "            ans_start_loss = loss_fct(ans_start_logits, ans_start)\n",
        "            ans_end_loss = loss_fct(ans_end_logits, ans_end)\n",
        "\n",
        "            loss = ans_start_loss + ans_end_loss\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if batch_id % 30 == 0 and batch_id != 0:\n",
        "                print('Validation Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "                    batch_id + 1, batch_id, running_loss / 30))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        print(\"evaluate loss: \", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCbdwah3bRir",
        "outputId": "d03bb816-a849-4bec-ebd2-137691bc9d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   1%|          | 101/12477 [00:26<55:58,  3.68it/s, loss=1.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101 Batch 100 Loss 1.9316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   2%|▏         | 201/12477 [00:54<55:43,  3.67it/s, loss=1.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201 Batch 200 Loss 1.4167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   2%|▏         | 301/12477 [01:21<54:41,  3.71it/s, loss=1.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301 Batch 300 Loss 1.7831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   3%|▎         | 401/12477 [01:48<53:53,  3.73it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401 Batch 400 Loss 1.4441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   4%|▍         | 501/12477 [02:15<54:11,  3.68it/s, loss=1.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 501 Batch 500 Loss 1.4316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   5%|▍         | 601/12477 [02:42<53:22,  3.71it/s, loss=1.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 601 Batch 600 Loss 1.4277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   6%|▌         | 701/12477 [03:09<53:05,  3.70it/s, loss=1.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 701 Batch 700 Loss 1.4157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   6%|▋         | 801/12477 [03:36<52:30,  3.71it/s, loss=1.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 801 Batch 800 Loss 1.3968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   7%|▋         | 901/12477 [04:03<52:18,  3.69it/s, loss=1.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 901 Batch 900 Loss 1.3910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   8%|▊         | 1001/12477 [04:30<51:32,  3.71it/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1001 Batch 1000 Loss 1.4035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   9%|▉         | 1101/12477 [04:57<51:23,  3.69it/s, loss=1.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1101 Batch 1100 Loss 1.3912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  10%|▉         | 1201/12477 [05:24<50:25,  3.73it/s, loss=1.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1201 Batch 1200 Loss 1.3952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  10%|█         | 1301/12477 [05:51<50:06,  3.72it/s, loss=1.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1301 Batch 1300 Loss 1.3939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  11%|█         | 1401/12477 [06:18<49:49,  3.71it/s, loss=1.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1401 Batch 1400 Loss 1.3980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  12%|█▏        | 1501/12477 [06:45<49:17,  3.71it/s, loss=1.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1501 Batch 1500 Loss 1.4284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  13%|█▎        | 1601/12477 [07:12<49:11,  3.69it/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1601 Batch 1600 Loss 1.3941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  14%|█▎        | 1701/12477 [07:39<48:49,  3.68it/s, loss=1.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1701 Batch 1700 Loss 1.3933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  14%|█▍        | 1801/12477 [08:06<48:06,  3.70it/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1801 Batch 1800 Loss 1.3968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  15%|█▌        | 1901/12477 [08:33<47:34,  3.70it/s, loss=1.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1901 Batch 1900 Loss 1.3919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  16%|█▌        | 2001/12477 [09:00<47:08,  3.70it/s, loss=1.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2001 Batch 2000 Loss 1.3965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  17%|█▋        | 2101/12477 [09:27<46:46,  3.70it/s, loss=1.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2101 Batch 2100 Loss 1.4328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  18%|█▊        | 2201/12477 [09:54<46:18,  3.70it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2201 Batch 2200 Loss 1.3924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  18%|█▊        | 2301/12477 [10:21<45:54,  3.69it/s, loss=1.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2301 Batch 2300 Loss 1.3946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  19%|█▉        | 2401/12477 [10:48<44:50,  3.75it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2401 Batch 2400 Loss 1.4254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  20%|██        | 2501/12477 [11:15<45:30,  3.65it/s, loss=1.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2501 Batch 2500 Loss 1.4206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  21%|██        | 2601/12477 [11:42<44:25,  3.71it/s, loss=1.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2601 Batch 2600 Loss 1.4078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  22%|██▏       | 2701/12477 [12:09<43:54,  3.71it/s, loss=1.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2701 Batch 2700 Loss 1.3978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  22%|██▏       | 2801/12477 [12:36<43:32,  3.70it/s, loss=1.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2801 Batch 2800 Loss 1.3961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  23%|██▎       | 2901/12477 [13:03<43:00,  3.71it/s, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2901 Batch 2900 Loss 1.3920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  24%|██▍       | 3001/12477 [13:30<42:50,  3.69it/s, loss=1.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3001 Batch 3000 Loss 1.4018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  25%|██▍       | 3101/12477 [13:57<42:11,  3.70it/s, loss=1.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3101 Batch 3100 Loss 1.3871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  26%|██▌       | 3201/12477 [14:24<41:42,  3.71it/s, loss=1.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3201 Batch 3200 Loss 1.4018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  26%|██▋       | 3301/12477 [14:51<41:28,  3.69it/s, loss=1.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3301 Batch 3300 Loss 1.4014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  27%|██▋       | 3401/12477 [15:18<40:50,  3.70it/s, loss=1.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3401 Batch 3400 Loss 1.3891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  28%|██▊       | 3501/12477 [15:45<40:20,  3.71it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3501 Batch 3500 Loss 1.3921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  29%|██▉       | 3601/12477 [16:12<39:40,  3.73it/s, loss=1.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3601 Batch 3600 Loss 1.3990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  30%|██▉       | 3701/12477 [16:39<39:32,  3.70it/s, loss=1.44]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3701 Batch 3700 Loss 1.3965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  30%|███       | 3801/12477 [17:06<39:10,  3.69it/s, loss=1.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3801 Batch 3800 Loss 1.3894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  31%|███▏      | 3901/12477 [17:33<38:38,  3.70it/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3901 Batch 3900 Loss 1.3899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  32%|███▏      | 4001/12477 [18:00<38:05,  3.71it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4001 Batch 4000 Loss 1.3936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  33%|███▎      | 4101/12477 [18:27<37:47,  3.69it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4101 Batch 4100 Loss 1.3967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  34%|███▎      | 4201/12477 [18:54<37:10,  3.71it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4201 Batch 4200 Loss 1.3980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  34%|███▍      | 4301/12477 [19:21<36:43,  3.71it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4301 Batch 4300 Loss 1.3935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  35%|███▌      | 4401/12477 [19:48<36:26,  3.69it/s, loss=1.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4401 Batch 4400 Loss 1.3853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  36%|███▌      | 4501/12477 [20:15<35:55,  3.70it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4501 Batch 4500 Loss 1.3926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  37%|███▋      | 4601/12477 [20:42<35:27,  3.70it/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4601 Batch 4600 Loss 1.3987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  38%|███▊      | 4701/12477 [21:09<34:55,  3.71it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4701 Batch 4700 Loss 1.3891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  38%|███▊      | 4801/12477 [21:36<34:39,  3.69it/s, loss=1.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4801 Batch 4800 Loss 1.3988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  39%|███▉      | 4901/12477 [22:03<34:08,  3.70it/s, loss=1.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4901 Batch 4900 Loss 1.3800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|████      | 5001/12477 [22:30<33:43,  3.69it/s, loss=1.44]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5001 Batch 5000 Loss 1.3867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  41%|████      | 5101/12477 [22:57<33:19,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5101 Batch 5100 Loss 10.1339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  42%|████▏     | 5201/12477 [23:24<32:41,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5201 Batch 5200 Loss 10.3631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  42%|████▏     | 5301/12477 [23:51<32:12,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5301 Batch 5300 Loss 10.3442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  43%|████▎     | 5401/12477 [24:18<31:50,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5401 Batch 5400 Loss 10.3457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  44%|████▍     | 5501/12477 [24:45<31:27,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5501 Batch 5500 Loss 10.3498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  45%|████▍     | 5601/12477 [25:12<31:02,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5601 Batch 5600 Loss 10.3412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  46%|████▌     | 5701/12477 [25:39<30:17,  3.73it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5701 Batch 5700 Loss 10.3530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  46%|████▋     | 5801/12477 [26:06<30:03,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5801 Batch 5800 Loss 10.3511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  47%|████▋     | 5901/12477 [26:33<29:35,  3.70it/s, loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5901 Batch 5900 Loss 10.3499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  48%|████▊     | 6001/12477 [27:00<29:02,  3.72it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6001 Batch 6000 Loss 10.3527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  49%|████▉     | 6101/12477 [27:27<28:54,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6101 Batch 6100 Loss 10.3375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  50%|████▉     | 6201/12477 [27:54<28:17,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6201 Batch 6200 Loss 10.3571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  51%|█████     | 6301/12477 [28:20<27:43,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6301 Batch 6300 Loss 10.3474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  51%|█████▏    | 6401/12477 [28:47<27:23,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6401 Batch 6400 Loss 10.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  52%|█████▏    | 6501/12477 [29:14<26:55,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6501 Batch 6500 Loss 10.3465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  53%|█████▎    | 6601/12477 [29:41<26:28,  3.70it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6601 Batch 6600 Loss 10.3457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  54%|█████▎    | 6701/12477 [30:08<25:57,  3.71it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6701 Batch 6700 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  55%|█████▍    | 6801/12477 [30:35<25:31,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6801 Batch 6800 Loss 10.3446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  55%|█████▌    | 6901/12477 [31:02<25:02,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6901 Batch 6900 Loss 10.3544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  56%|█████▌    | 7001/12477 [31:29<24:38,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7001 Batch 7000 Loss 10.3375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  57%|█████▋    | 7101/12477 [31:56<24:05,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7101 Batch 7100 Loss 10.3386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  58%|█████▊    | 7201/12477 [32:23<23:40,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7201 Batch 7200 Loss 10.3508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  59%|█████▊    | 7301/12477 [32:50<23:18,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7301 Batch 7300 Loss 10.3535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  59%|█████▉    | 7401/12477 [33:17<22:46,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7401 Batch 7400 Loss 10.3568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|██████    | 7501/12477 [33:44<22:14,  3.73it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7501 Batch 7500 Loss 10.3448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  61%|██████    | 7601/12477 [34:11<22:00,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7601 Batch 7600 Loss 10.3576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  62%|██████▏   | 7701/12477 [34:38<21:26,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7701 Batch 7700 Loss 10.3487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  63%|██████▎   | 7801/12477 [35:05<21:01,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7801 Batch 7800 Loss 10.3506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  63%|██████▎   | 7901/12477 [35:32<20:46,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7901 Batch 7900 Loss 10.3467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  64%|██████▍   | 8001/12477 [35:59<20:19,  3.67it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8001 Batch 8000 Loss 10.3488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  65%|██████▍   | 8101/12477 [36:26<19:37,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8101 Batch 8100 Loss 10.3443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  66%|██████▌   | 8201/12477 [36:53<19:16,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8201 Batch 8200 Loss 10.3477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  67%|██████▋   | 8301/12477 [37:20<18:51,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8301 Batch 8300 Loss 10.3515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  67%|██████▋   | 8401/12477 [37:47<18:22,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8401 Batch 8400 Loss 10.3503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  68%|██████▊   | 8501/12477 [38:14<17:55,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8501 Batch 8500 Loss 10.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  69%|██████▉   | 8601/12477 [38:41<17:35,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8601 Batch 8600 Loss 10.3370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  70%|██████▉   | 8701/12477 [39:08<17:04,  3.69it/s, loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8701 Batch 8700 Loss 10.3564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  71%|███████   | 8801/12477 [39:35<16:38,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8801 Batch 8800 Loss 10.3472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  71%|███████▏  | 8901/12477 [40:02<16:06,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8901 Batch 8900 Loss 10.3498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  72%|███████▏  | 9001/12477 [40:29<15:39,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9001 Batch 9000 Loss 10.3443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  73%|███████▎  | 9101/12477 [40:56<15:16,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9101 Batch 9100 Loss 10.3403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  74%|███████▎  | 9201/12477 [41:23<14:42,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9201 Batch 9200 Loss 10.3390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  75%|███████▍  | 9301/12477 [41:50<14:19,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9301 Batch 9300 Loss 10.3512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  75%|███████▌  | 9401/12477 [42:17<13:49,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9401 Batch 9400 Loss 10.3560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  76%|███████▌  | 9501/12477 [42:44<13:20,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9501 Batch 9500 Loss 10.3456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  77%|███████▋  | 9601/12477 [43:11<12:54,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9601 Batch 9600 Loss 10.3460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  78%|███████▊  | 9701/12477 [43:38<12:28,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9701 Batch 9700 Loss 10.3538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  79%|███████▊  | 9801/12477 [44:04<12:00,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9801 Batch 9800 Loss 10.3586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  79%|███████▉  | 9901/12477 [44:31<11:34,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9901 Batch 9900 Loss 10.3531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|████████  | 10001/12477 [44:58<11:09,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10001 Batch 10000 Loss 10.3496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  81%|████████  | 10101/12477 [45:25<10:38,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10101 Batch 10100 Loss 10.3468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  82%|████████▏ | 10201/12477 [45:52<10:15,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10201 Batch 10200 Loss 10.3418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  83%|████████▎ | 10301/12477 [46:19<09:47,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10301 Batch 10300 Loss 10.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  83%|████████▎ | 10401/12477 [46:46<09:19,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10401 Batch 10400 Loss 10.3447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  84%|████████▍ | 10501/12477 [47:13<08:59,  3.66it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10501 Batch 10500 Loss 10.3459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  85%|████████▍ | 10601/12477 [47:40<08:25,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10601 Batch 10600 Loss 10.3402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  86%|████████▌ | 10701/12477 [48:07<08:00,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10701 Batch 10700 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  87%|████████▋ | 10801/12477 [48:34<07:31,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10801 Batch 10800 Loss 10.3429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  87%|████████▋ | 10901/12477 [49:01<07:06,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10901 Batch 10900 Loss 10.3472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  88%|████████▊ | 11001/12477 [49:28<06:38,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11001 Batch 11000 Loss 10.3445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  89%|████████▉ | 11101/12477 [49:55<06:09,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11101 Batch 11100 Loss 10.3424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  90%|████████▉ | 11201/12477 [50:22<05:45,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11201 Batch 11200 Loss 10.3586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  91%|█████████ | 11301/12477 [50:49<05:17,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11301 Batch 11300 Loss 10.3478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  91%|█████████▏| 11401/12477 [51:16<04:50,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11401 Batch 11400 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  92%|█████████▏| 11501/12477 [51:43<04:23,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11501 Batch 11500 Loss 10.3392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  93%|█████████▎| 11601/12477 [52:10<03:57,  3.69it/s, loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11601 Batch 11600 Loss 10.3403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  94%|█████████▍| 11701/12477 [52:37<03:29,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11701 Batch 11700 Loss 10.3516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  95%|█████████▍| 11801/12477 [53:04<03:02,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11801 Batch 11800 Loss 10.3526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  95%|█████████▌| 11901/12477 [53:31<02:36,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11901 Batch 11900 Loss 10.3536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  96%|█████████▌| 12001/12477 [53:58<02:08,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12001 Batch 12000 Loss 10.3498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  97%|█████████▋| 12101/12477 [54:25<01:41,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12101 Batch 12100 Loss 10.3455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  98%|█████████▊| 12201/12477 [54:52<01:14,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12201 Batch 12200 Loss 10.3437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  99%|█████████▊| 12301/12477 [55:19<00:47,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12301 Batch 12300 Loss 10.3471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  99%|█████████▉| 12401/12477 [55:46<00:20,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12401 Batch 12400 Loss 10.3506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 12477/12477 [56:07<00:00,  3.71it/s, loss=10.3]\n",
            "  2%|▏         | 32/1737 [00:02<02:15, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 31 Batch 30 Loss 10.5397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 62/1737 [00:04<02:12, 12.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 61 Batch 60 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 92/1737 [00:07<02:12, 12.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 91 Batch 90 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 122/1737 [00:09<02:10, 12.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 121 Batch 120 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 152/1737 [00:12<02:06, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 151 Batch 150 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 182/1737 [00:14<02:04, 12.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 181 Batch 180 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 212/1737 [00:16<02:02, 12.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 211 Batch 210 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 242/1737 [00:19<02:00, 12.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 241 Batch 240 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 272/1737 [00:21<01:56, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 271 Batch 270 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 302/1737 [00:24<01:55, 12.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 301 Batch 300 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 332/1737 [00:26<01:52, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 331 Batch 330 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 362/1737 [00:28<01:51, 12.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 361 Batch 360 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 392/1737 [00:31<01:47, 12.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 391 Batch 390 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 422/1737 [00:33<01:45, 12.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 421 Batch 420 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 452/1737 [00:36<01:43, 12.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 451 Batch 450 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 482/1737 [00:38<01:39, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 481 Batch 480 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 512/1737 [00:40<01:38, 12.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 511 Batch 510 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 542/1737 [00:43<01:35, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 541 Batch 540 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 572/1737 [00:45<01:33, 12.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 571 Batch 570 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 602/1737 [00:48<01:30, 12.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 601 Batch 600 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 632/1737 [00:50<01:28, 12.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 631 Batch 630 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 662/1737 [00:53<01:26, 12.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 661 Batch 660 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 692/1737 [00:55<01:23, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 691 Batch 690 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 722/1737 [00:57<01:20, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 721 Batch 720 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 752/1737 [01:00<01:19, 12.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 751 Batch 750 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 782/1737 [01:02<01:16, 12.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 781 Batch 780 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 812/1737 [01:05<01:14, 12.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 811 Batch 810 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 842/1737 [01:07<01:11, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 841 Batch 840 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 872/1737 [01:09<01:09, 12.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 871 Batch 870 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 902/1737 [01:12<01:07, 12.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 901 Batch 900 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 932/1737 [01:14<01:05, 12.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 931 Batch 930 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 962/1737 [01:17<01:02, 12.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 961 Batch 960 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 992/1737 [01:19<00:59, 12.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 991 Batch 990 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1022/1737 [01:21<00:57, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1021 Batch 1020 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 1052/1737 [01:24<00:54, 12.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1051 Batch 1050 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 1082/1737 [01:26<00:52, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1081 Batch 1080 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1112/1737 [01:29<00:50, 12.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1111 Batch 1110 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 1142/1737 [01:31<00:48, 12.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1141 Batch 1140 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1172/1737 [01:33<00:45, 12.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1171 Batch 1170 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1202/1737 [01:36<00:42, 12.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1201 Batch 1200 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 1232/1737 [01:38<00:40, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1231 Batch 1230 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 1262/1737 [01:41<00:38, 12.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1261 Batch 1260 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 1292/1737 [01:43<00:35, 12.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1291 Batch 1290 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 1322/1737 [01:46<00:33, 12.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1321 Batch 1320 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1352/1737 [01:48<00:30, 12.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1351 Batch 1350 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 1382/1737 [01:50<00:28, 12.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1381 Batch 1380 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 1412/1737 [01:53<00:26, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1411 Batch 1410 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1442/1737 [01:55<00:23, 12.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1441 Batch 1440 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1472/1737 [01:58<00:21, 12.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1471 Batch 1470 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 1502/1737 [02:00<00:18, 12.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1501 Batch 1500 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1532/1737 [02:02<00:16, 12.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1531 Batch 1530 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1562/1737 [02:05<00:14, 12.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1561 Batch 1560 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1592/1737 [02:07<00:11, 12.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1591 Batch 1590 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1622/1737 [02:10<00:09, 12.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1621 Batch 1620 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1652/1737 [02:12<00:06, 12.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1651 Batch 1650 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 1682/1737 [02:15<00:04, 12.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1681 Batch 1680 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 1712/1737 [02:17<00:02, 12.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1711 Batch 1710 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1737/1737 [02:19<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluate loss:  tensor(10.1997, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   1%|          | 101/12477 [00:27<56:06,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101 Batch 100 Loss 10.4556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   2%|▏         | 201/12477 [00:54<54:51,  3.73it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201 Batch 200 Loss 10.3445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   2%|▏         | 301/12477 [01:21<54:41,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301 Batch 300 Loss 10.3438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   3%|▎         | 401/12477 [01:48<54:41,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401 Batch 400 Loss 10.3473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   4%|▍         | 501/12477 [02:15<54:07,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 501 Batch 500 Loss 10.3387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   5%|▍         | 601/12477 [02:42<53:20,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 601 Batch 600 Loss 10.3434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   6%|▌         | 701/12477 [03:09<53:11,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 701 Batch 700 Loss 10.3479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   6%|▋         | 801/12477 [03:36<52:42,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 801 Batch 800 Loss 10.3422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   7%|▋         | 901/12477 [04:03<52:15,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 901 Batch 900 Loss 10.3462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   8%|▊         | 1001/12477 [04:30<51:54,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1001 Batch 1000 Loss 10.3500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   9%|▉         | 1101/12477 [04:57<51:11,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1101 Batch 1100 Loss 10.3545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  10%|▉         | 1201/12477 [05:24<50:40,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1201 Batch 1200 Loss 10.3453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  10%|█         | 1301/12477 [05:51<50:33,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1301 Batch 1300 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  11%|█         | 1401/12477 [06:18<49:30,  3.73it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1401 Batch 1400 Loss 10.3502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  12%|█▏        | 1501/12477 [06:45<49:36,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1501 Batch 1500 Loss 10.3557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  13%|█▎        | 1601/12477 [07:12<49:09,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1601 Batch 1600 Loss 10.3394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  14%|█▎        | 1701/12477 [07:39<48:38,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1701 Batch 1700 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  14%|█▍        | 1801/12477 [08:06<48:01,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1801 Batch 1800 Loss 10.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  15%|█▌        | 1901/12477 [08:33<47:49,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1901 Batch 1900 Loss 10.3460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  16%|█▌        | 2001/12477 [09:01<46:52,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2001 Batch 2000 Loss 10.3461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  17%|█▋        | 2101/12477 [09:28<46:39,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2101 Batch 2100 Loss 10.3459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  18%|█▊        | 2201/12477 [09:55<46:05,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2201 Batch 2200 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  18%|█▊        | 2301/12477 [10:22<45:58,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2301 Batch 2300 Loss 10.3506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  19%|█▉        | 2401/12477 [10:49<45:30,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2401 Batch 2400 Loss 10.3425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  20%|██        | 2501/12477 [11:16<44:51,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2501 Batch 2500 Loss 10.3440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  21%|██        | 2601/12477 [11:43<44:37,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2601 Batch 2600 Loss 10.3538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  22%|██▏       | 2701/12477 [12:10<44:15,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2701 Batch 2700 Loss 10.3507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  22%|██▏       | 2801/12477 [12:37<43:23,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2801 Batch 2800 Loss 10.3475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  23%|██▎       | 2901/12477 [13:04<43:07,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2901 Batch 2900 Loss 10.3368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  24%|██▍       | 3001/12477 [13:31<42:47,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3001 Batch 3000 Loss 10.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  25%|██▍       | 3101/12477 [13:58<42:14,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3101 Batch 3100 Loss 10.3467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  26%|██▌       | 3201/12477 [14:25<41:41,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3201 Batch 3200 Loss 10.3434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  26%|██▋       | 3301/12477 [14:52<41:15,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3301 Batch 3300 Loss 10.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  27%|██▋       | 3401/12477 [15:19<41:05,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3401 Batch 3400 Loss 10.3470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  28%|██▊       | 3501/12477 [15:46<41:03,  3.64it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3501 Batch 3500 Loss 10.3511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  29%|██▉       | 3601/12477 [16:13<40:10,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3601 Batch 3600 Loss 10.3457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  30%|██▉       | 3701/12477 [16:40<39:43,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3701 Batch 3700 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  30%|███       | 3801/12477 [17:07<39:02,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3801 Batch 3800 Loss 10.3476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  31%|███▏      | 3901/12477 [17:34<38:52,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3901 Batch 3900 Loss 10.3514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  32%|███▏      | 4001/12477 [18:01<38:22,  3.68it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4001 Batch 4000 Loss 10.3406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  33%|███▎      | 4101/12477 [18:28<37:50,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4101 Batch 4100 Loss 10.3531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  34%|███▎      | 4201/12477 [18:55<37:39,  3.66it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4201 Batch 4200 Loss 10.3522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  34%|███▍      | 4301/12477 [19:22<36:59,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4301 Batch 4300 Loss 10.3423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  35%|███▌      | 4401/12477 [19:49<36:37,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4401 Batch 4400 Loss 10.3456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  36%|███▌      | 4501/12477 [20:16<36:06,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4501 Batch 4500 Loss 10.3502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  37%|███▋      | 4601/12477 [20:43<35:27,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4601 Batch 4600 Loss 10.3406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  38%|███▊      | 4701/12477 [21:11<35:09,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4701 Batch 4700 Loss 10.3475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  38%|███▊      | 4801/12477 [21:38<34:37,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4801 Batch 4800 Loss 10.3494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  39%|███▉      | 4901/12477 [22:05<34:01,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4901 Batch 4900 Loss 10.3432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|████      | 5001/12477 [22:32<33:55,  3.67it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5001 Batch 5000 Loss 10.3478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  41%|████      | 5101/12477 [22:59<33:06,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5101 Batch 5100 Loss 10.3406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  42%|████▏     | 5201/12477 [23:26<32:51,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5201 Batch 5200 Loss 10.3458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  42%|████▏     | 5301/12477 [23:53<32:14,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5301 Batch 5300 Loss 10.3405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  43%|████▎     | 5401/12477 [24:20<31:47,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5401 Batch 5400 Loss 10.3376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  44%|████▍     | 5501/12477 [24:47<31:26,  3.70it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5501 Batch 5500 Loss 10.3434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  45%|████▍     | 5601/12477 [25:14<30:56,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5601 Batch 5600 Loss 10.3443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  46%|████▌     | 5701/12477 [25:41<30:15,  3.73it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5701 Batch 5700 Loss 10.3442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  46%|████▋     | 5801/12477 [26:08<30:05,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5801 Batch 5800 Loss 10.3405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  47%|████▋     | 5901/12477 [26:35<29:16,  3.74it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5901 Batch 5900 Loss 10.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  48%|████▊     | 6001/12477 [27:02<29:03,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6001 Batch 6000 Loss 10.3424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  49%|████▉     | 6101/12477 [27:29<28:43,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6101 Batch 6100 Loss 10.3471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  50%|████▉     | 6201/12477 [27:56<28:38,  3.65it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6201 Batch 6200 Loss 10.3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  51%|█████     | 6301/12477 [28:23<28:00,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6301 Batch 6300 Loss 10.3461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  51%|█████▏    | 6401/12477 [28:50<27:13,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6401 Batch 6400 Loss 10.3438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  52%|█████▏    | 6501/12477 [29:17<26:56,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6501 Batch 6500 Loss 10.3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  53%|█████▎    | 6601/12477 [29:44<26:40,  3.67it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6601 Batch 6600 Loss 10.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  54%|█████▎    | 6701/12477 [30:11<26:08,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6701 Batch 6700 Loss 10.3484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  55%|█████▍    | 6801/12477 [30:38<25:33,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6801 Batch 6800 Loss 10.3489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  55%|█████▌    | 6901/12477 [31:05<25:20,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6901 Batch 6900 Loss 10.3372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  56%|█████▌    | 7001/12477 [31:32<24:32,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7001 Batch 7000 Loss 10.3390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  57%|█████▋    | 7101/12477 [31:59<24:28,  3.66it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7101 Batch 7100 Loss 10.3440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  58%|█████▊    | 7201/12477 [32:27<23:40,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7201 Batch 7200 Loss 10.3509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  59%|█████▊    | 7301/12477 [32:54<23:32,  3.66it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7301 Batch 7300 Loss 10.3464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  59%|█████▉    | 7401/12477 [33:21<22:54,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7401 Batch 7400 Loss 10.3482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  60%|██████    | 7501/12477 [33:48<22:29,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7501 Batch 7500 Loss 10.3463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  61%|██████    | 7601/12477 [34:15<21:42,  3.74it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7601 Batch 7600 Loss 10.3398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  62%|██████▏   | 7701/12477 [34:42<21:37,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7701 Batch 7700 Loss 10.3502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  63%|██████▎   | 7801/12477 [35:09<21:00,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7801 Batch 7800 Loss 10.3494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  63%|██████▎   | 7901/12477 [35:36<20:42,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7901 Batch 7900 Loss 10.3447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  64%|██████▍   | 8001/12477 [36:03<20:24,  3.66it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8001 Batch 8000 Loss 10.3454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  65%|██████▍   | 8101/12477 [36:30<19:47,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8101 Batch 8100 Loss 10.3483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  66%|██████▌   | 8201/12477 [36:57<19:10,  3.72it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8201 Batch 8200 Loss 10.3417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  67%|██████▋   | 8301/12477 [37:24<18:56,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8301 Batch 8300 Loss 10.3368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  67%|██████▋   | 8401/12477 [37:51<18:27,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8401 Batch 8400 Loss 10.3547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  68%|██████▊   | 8501/12477 [38:18<18:09,  3.65it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8501 Batch 8500 Loss 10.3492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  69%|██████▉   | 8601/12477 [38:45<17:23,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8601 Batch 8600 Loss 10.3392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  70%|██████▉   | 8701/12477 [39:12<16:54,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8701 Batch 8700 Loss 10.3466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  71%|███████   | 8801/12477 [39:39<16:39,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8801 Batch 8800 Loss 10.3492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  71%|███████▏  | 8901/12477 [40:06<16:08,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8901 Batch 8900 Loss 10.3462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  72%|███████▏  | 9001/12477 [40:33<15:33,  3.72it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9001 Batch 9000 Loss 10.3502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  73%|███████▎  | 9101/12477 [41:01<15:15,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9101 Batch 9100 Loss 10.3367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  74%|███████▎  | 9201/12477 [41:28<14:46,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9201 Batch 9200 Loss 10.3429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  75%|███████▍  | 9301/12477 [41:55<14:29,  3.65it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9301 Batch 9300 Loss 10.3471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  75%|███████▌  | 9401/12477 [42:22<13:49,  3.71it/s, loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9401 Batch 9400 Loss 10.3481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  76%|███████▌  | 9501/12477 [42:49<13:18,  3.73it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9501 Batch 9500 Loss 10.3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  77%|███████▋  | 9601/12477 [43:16<13:01,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9601 Batch 9600 Loss 10.3516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  78%|███████▊  | 9701/12477 [43:43<12:33,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9701 Batch 9700 Loss 10.3505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  79%|███████▊  | 9801/12477 [44:10<12:04,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9801 Batch 9800 Loss 10.3566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  79%|███████▉  | 9901/12477 [44:37<11:40,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9901 Batch 9900 Loss 10.3605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|████████  | 10001/12477 [45:04<11:17,  3.65it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10001 Batch 10000 Loss 10.3501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  81%|████████  | 10101/12477 [45:31<10:43,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10101 Batch 10100 Loss 10.3542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  82%|████████▏ | 10201/12477 [45:59<10:18,  3.68it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10201 Batch 10200 Loss 10.3485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  83%|████████▎ | 10301/12477 [46:26<09:50,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10301 Batch 10300 Loss 10.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  83%|████████▎ | 10401/12477 [46:53<09:21,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10401 Batch 10400 Loss 10.3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  84%|████████▍ | 10501/12477 [47:20<08:53,  3.70it/s, loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10501 Batch 10500 Loss 10.3519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  85%|████████▍ | 10601/12477 [47:47<08:26,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10601 Batch 10600 Loss 10.3522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  86%|████████▌ | 10701/12477 [48:14<07:58,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10701 Batch 10700 Loss 10.3336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  87%|████████▋ | 10801/12477 [48:41<07:35,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10801 Batch 10800 Loss 10.3451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  87%|████████▋ | 10901/12477 [49:08<07:09,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10901 Batch 10900 Loss 10.3459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  88%|████████▊ | 11001/12477 [49:35<06:38,  3.71it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11001 Batch 11000 Loss 10.3460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  89%|████████▉ | 11101/12477 [50:02<06:11,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11101 Batch 11100 Loss 10.3424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  90%|████████▉ | 11201/12477 [50:29<05:43,  3.71it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11201 Batch 11200 Loss 10.3563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  91%|█████████ | 11301/12477 [50:56<05:17,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11301 Batch 11300 Loss 10.3378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  91%|█████████▏| 11401/12477 [51:24<04:53,  3.67it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11401 Batch 11400 Loss 10.3493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  92%|█████████▏| 11501/12477 [51:51<04:25,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11501 Batch 11500 Loss 10.3471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  93%|█████████▎| 11601/12477 [52:18<03:59,  3.66it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11601 Batch 11600 Loss 10.3380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  94%|█████████▍| 11701/12477 [52:45<03:31,  3.68it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11701 Batch 11700 Loss 10.3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  95%|█████████▍| 11801/12477 [53:12<03:03,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11801 Batch 11800 Loss 10.3489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  95%|█████████▌| 11901/12477 [53:39<02:36,  3.68it/s, loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11901 Batch 11900 Loss 10.3588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  96%|█████████▌| 12001/12477 [54:06<02:08,  3.70it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12001 Batch 12000 Loss 10.3497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  97%|█████████▋| 12101/12477 [54:33<01:41,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12101 Batch 12100 Loss 10.3422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  98%|█████████▊| 12201/12477 [55:00<01:14,  3.69it/s, loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12201 Batch 12200 Loss 10.3535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  99%|█████████▊| 12301/12477 [55:27<00:47,  3.70it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12301 Batch 12300 Loss 10.3580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  99%|█████████▉| 12401/12477 [55:54<00:20,  3.69it/s, loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12401 Batch 12400 Loss 10.3530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 12477/12477 [56:15<00:00,  3.70it/s, loss=10.5]\n",
            "  2%|▏         | 32/1737 [00:02<02:14, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 31 Batch 30 Loss 10.5397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 62/1737 [00:04<02:13, 12.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 61 Batch 60 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 92/1737 [00:07<02:11, 12.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 91 Batch 90 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 122/1737 [00:09<02:07, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 121 Batch 120 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 152/1737 [00:12<02:07, 12.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 151 Batch 150 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 182/1737 [00:14<02:04, 12.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 181 Batch 180 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 212/1737 [00:16<02:00, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 211 Batch 210 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 242/1737 [00:19<01:59, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 241 Batch 240 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 272/1737 [00:21<01:55, 12.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 271 Batch 270 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 302/1737 [00:24<01:53, 12.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 301 Batch 300 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 332/1737 [00:26<01:51, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 331 Batch 330 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 362/1737 [00:28<01:49, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 361 Batch 360 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 392/1737 [00:31<01:46, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 391 Batch 390 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 422/1737 [00:33<01:43, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 421 Batch 420 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 452/1737 [00:35<01:41, 12.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 451 Batch 450 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 482/1737 [00:38<01:39, 12.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 481 Batch 480 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 512/1737 [00:40<01:37, 12.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 511 Batch 510 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 542/1737 [00:43<01:34, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 541 Batch 540 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 572/1737 [00:45<01:32, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 571 Batch 570 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 602/1737 [00:47<01:29, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 601 Batch 600 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 632/1737 [00:50<01:28, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 631 Batch 630 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 662/1737 [00:52<01:25, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 661 Batch 660 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 692/1737 [00:55<01:22, 12.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 691 Batch 690 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 722/1737 [00:57<01:20, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 721 Batch 720 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 752/1737 [00:59<01:18, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 751 Batch 750 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 782/1737 [01:02<01:16, 12.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 781 Batch 780 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 812/1737 [01:04<01:13, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 811 Batch 810 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 842/1737 [01:06<01:10, 12.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 841 Batch 840 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 872/1737 [01:09<01:08, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 871 Batch 870 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 902/1737 [01:11<01:06, 12.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 901 Batch 900 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 932/1737 [01:14<01:03, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 931 Batch 930 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 962/1737 [01:16<01:01, 12.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 961 Batch 960 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 992/1737 [01:18<00:58, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 991 Batch 990 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1022/1737 [01:21<00:56, 12.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1021 Batch 1020 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 1052/1737 [01:23<00:53, 12.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1051 Batch 1050 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 1082/1737 [01:26<00:51, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1081 Batch 1080 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1112/1737 [01:28<00:49, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1111 Batch 1110 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 1142/1737 [01:30<00:47, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1141 Batch 1140 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 1172/1737 [01:33<00:44, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1171 Batch 1170 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1202/1737 [01:35<00:42, 12.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1201 Batch 1200 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 1232/1737 [01:37<00:40, 12.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1231 Batch 1230 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 1262/1737 [01:40<00:38, 12.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1261 Batch 1260 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 1292/1737 [01:42<00:35, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1291 Batch 1290 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 1322/1737 [01:45<00:32, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1321 Batch 1320 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 1352/1737 [01:47<00:30, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1351 Batch 1350 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 1382/1737 [01:49<00:28, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1381 Batch 1380 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 1412/1737 [01:52<00:25, 12.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1411 Batch 1410 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1442/1737 [01:54<00:23, 12.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1441 Batch 1440 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1472/1737 [01:57<00:20, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1471 Batch 1470 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 1502/1737 [01:59<00:18, 12.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1501 Batch 1500 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1532/1737 [02:01<00:16, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1531 Batch 1530 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 1562/1737 [02:04<00:13, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1561 Batch 1560 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1592/1737 [02:06<00:11, 12.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1591 Batch 1590 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1622/1737 [02:08<00:09, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1621 Batch 1620 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1652/1737 [02:11<00:06, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1651 Batch 1650 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 1682/1737 [02:13<00:04, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1681 Batch 1680 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 1712/1737 [02:16<00:01, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Epoch 1711 Batch 1710 Loss 10.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1737/1737 [02:18<00:00, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluate loss:  tensor(10.1997, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(training_epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        # reset\n",
        "        optim.zero_grad()\n",
        "\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        ans_start = batch['ans_start'].to(device)\n",
        "        ans_end = batch['ans_end'].to(device)\n",
        "\n",
        "\n",
        "        # model output\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        ans_start_logits, ans_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        ans_start_logits = ans_start_logits.squeeze(-1).contiguous()\n",
        "        ans_end_logits = ans_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        ans_start_loss = loss_fct(ans_start_logits, ans_start)\n",
        "        ans_end_loss = loss_fct(ans_end_logits, ans_end)\n",
        "\n",
        "\n",
        "\n",
        "        loss = ans_start_loss + ans_end_loss\n",
        "\n",
        "        # calculate loss\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if batch_id % 100 == 0 and batch_id != 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "                batch_id + 1, batch_id, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    evaluate(valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/NLP_assignment2/aicup_model')"
      ],
      "metadata": {
        "id": "WHsjSzV1ikU7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = myModel().to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/NLP_assignment2/aicup_model'))"
      ],
      "metadata": {
        "id": "rYDw03E9jrrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279cd34e-f76d-41c9-93b1-2d9b69884ed2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "dSC8u0sXjwrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_loader):\n",
        "    predict_pos = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    ans_sub_output = []\n",
        "\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "        # model output\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        \n",
        "        ans_start_logits, ans_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        ans_start_logits = ans_start_logits.squeeze(-1).contiguous()\n",
        "        ans_end_logits = ans_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        ans_start_prdict = torch.argmax(ans_start_logits, 1).cpu().numpy()\n",
        "        ans_end_prdict = torch.argmax(ans_end_logits, 1).cpu().numpy()\n",
        "\n",
        "        for i in range(len(input_ids)):\n",
        "            predict_pos.append((ans_start_prdict[i].item(), ans_end_prdict[i].item()))\n",
        "\n",
        "            ans_sub = tokenizer.decode(input_ids[i][ans_start_prdict[i]:ans_end_prdict[i]+1])\n",
        "            \n",
        "            ans_sub_output.append(ans_sub)\n",
        "    \n",
        "    return ans_sub_output, predict_pos"
      ],
      "metadata": {
        "id": "kSFX9gd3jvo7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans_sub_output, predict_pos = predict(valid_loader)"
      ],
      "metadata": {
        "id": "jQbBIbeekyBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0a1bd6-42a7-4810-b5ad-3eb8eb732956"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1737/1737 [02:19<00:00, 12.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_post_fn(test, ans_sub_output):\n",
        "    ans_sub = []\n",
        "    for i in range(len(test)):\n",
        "\n",
        "        ans_sub_pred = ans_sub_output[i].split()\n",
        "\n",
        "        if ans_sub_pred is None:\n",
        "            ans_sub_pred = []\n",
        "        ans_sub_error_index = ans_sub_pred.index('[SEP]') if '[SEP]' in ans_sub_pred else -1\n",
        "\n",
        "        if ans_sub_error_index != -1:\n",
        "            ans_sub_pred = ans_sub_pred[:ans_sub_error_index]\n",
        "\n",
        "\n",
        "        ans_sub.append(' '.join(ans_sub_pred))\n",
        "\n",
        "    return ans_sub"
      ],
      "metadata": {
        "id": "UzDu4ygok-9-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans_sub = get_output_post_fn(valid_df, ans_sub_output)"
      ],
      "metadata": {
        "id": "4D-j5gwXT6HF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df['ans_sub'] = ans_sub"
      ],
      "metadata": {
        "id": "bt3hXZeJUujl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "6uJoRsplU4ad",
        "outputId": "2cdbfa5a-c8ef-49f1-ce46-229fb06c3b88"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             snippet  \\\n",
              "0  free flashcards authors studystack spain 1959 ...   \n",
              "1  lowest highest death valley mt whitney walk ba...   \n",
              "2  banking peril barron 's apr 5 , 2010 take hub ...   \n",
              "3  direct essays mickey mouse steamboat willie ka...   \n",
              "4  old world capitals eastern europe vacations , ...   \n",
              "\n",
              "                                            question       answer  ans_start  \\\n",
              "0  spain 1959 , wrote dangerous summer , story ri...    hemingway        163   \n",
              "1  valley 282 feet sea level state lowest point w...   california          0   \n",
              "2  like banks , many grocery stores dispensing ca...         atms          0   \n",
              "3               voice mickey mouse steamboat willie   walt disney          0   \n",
              "4         eastern european capital city 2 2 million     bucharest          0   \n",
              "\n",
              "   ans_end                                            ans_sub  \n",
              "0      171                                                     \n",
              "1        0                                                     \n",
              "2        0               ? secret leaf lard, rendered 8 hours  \n",
              "3        0  [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD...  \n",
              "4        0                                               name  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39e365fe-c5ba-458b-b64a-1dfa1c3b7ce9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snippet</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>ans_start</th>\n",
              "      <th>ans_end</th>\n",
              "      <th>ans_sub</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>free flashcards authors studystack spain 1959 ...</td>\n",
              "      <td>spain 1959 , wrote dangerous summer , story ri...</td>\n",
              "      <td>hemingway</td>\n",
              "      <td>163</td>\n",
              "      <td>171</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lowest highest death valley mt whitney walk ba...</td>\n",
              "      <td>valley 282 feet sea level state lowest point w...</td>\n",
              "      <td>california</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>banking peril barron 's apr 5 , 2010 take hub ...</td>\n",
              "      <td>like banks , many grocery stores dispensing ca...</td>\n",
              "      <td>atms</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>? secret leaf lard, rendered 8 hours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>direct essays mickey mouse steamboat willie ka...</td>\n",
              "      <td>voice mickey mouse steamboat willie</td>\n",
              "      <td>walt disney</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>old world capitals eastern europe vacations , ...</td>\n",
              "      <td>eastern european capital city 2 2 million</td>\n",
              "      <td>bucharest</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39e365fe-c5ba-458b-b64a-1dfa1c3b7ce9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39e365fe-c5ba-458b-b64a-1dfa1c3b7ce9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39e365fe-c5ba-458b-b64a-1dfa1c3b7ce9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk_token_string(sentence):\n",
        "    # print(sentence)\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    for i in range(len(tokens)):\n",
        "        if len(tokens[i]) == 1:\n",
        "            tokens[i] = re.sub(r\"[!\\\"#$%&\\'()*\\+, -.\\/:;<=>?@\\[\\\\\\]^_`{|}~]\", '', tokens[i])\n",
        "    while '' in tokens:\n",
        "        tokens.remove('')\n",
        "    tokens = ' '.join(tokens)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "O0BZIwBXU8j9"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lcs(X, Y):\n",
        "    X_, Y_ = [], []\n",
        "    \n",
        "    X_ = nltk_token_string(X)\n",
        "    Y_ = nltk_token_string(Y)\n",
        "\n",
        "    m = len(X_)\n",
        "    n = len(Y_)\n",
        " \n",
        "    # declaring the array for storing the dp values\n",
        "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
        " \n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
        "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
        "    and Y[0..j-1]\"\"\"\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0 or j == 0 :\n",
        "                L[i][j] = 0\n",
        "            elif X_[i-1] == Y_[j-1]:\n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else:\n",
        "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
        " \n",
        "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
        "    return L[m][n]\n",
        "\n",
        "\n",
        "def acc(full, sub):\n",
        "    common = lcs(full, sub)\n",
        "    union = len(full) + len(sub) - common\n",
        "    accuracy = float(common/union)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "HL9QDls3VAFF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans_acc_sum = 0\n",
        "for i in range(valid_df.shape[0]):\n",
        "    ans_accuracy = acc(valid_df.iloc[i][\"answer\"], valid_df.iloc[i]['ans_sub'])\n",
        "\n",
        "    ans_acc_sum += ans_accuracy\n",
        "\n",
        "print(\"answer accuracy: \", ans_acc_sum/valid_df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zAe0bCAVCVF",
        "outputId": "a0031d84-12c1-4948-fc3b-60618e074835"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer accuracy:  0.05271999862862745\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIoau3circ2QLF39nhhZRS",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}